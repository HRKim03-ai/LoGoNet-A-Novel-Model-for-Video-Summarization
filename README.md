# Video Summarization Models Comparison

ë¹„ë””ì˜¤ ìš”ì•½ íƒœìŠ¤í¬ë¥¼ ìœ„í•œ 4ê°€ì§€ ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬í˜„ ë° ë¹„êµ ì‹¤í—˜ í”„ë¡œì íŠ¸

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” MR.HiSum ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ 4ê°€ì§€ ë¹„ë””ì˜¤ ìš”ì•½ ëª¨ë¸(CSTA, VideoSAGE, EDSNet, LoGoNet)ì„ êµ¬í˜„í•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤. íŠ¹íˆ **LoGoNet**ì´ë¼ëŠ” ìƒˆë¡œìš´ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•˜ì—¬ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ì„±ê³¼

### ì‹¤í—˜ ê²°ê³¼ (Test Set)

| Model | Test Loss | Kendall's Tau | Spearman's Rho | ìˆœìœ„ |
|-------|-----------|---------------|----------------|------|
| **LoGoNet** (ì œì•ˆ) | 0.0632 | **0.1336** | **0.1909** | **1ìœ„** |
| **CSTA** | 0.0579 | 0.1196 | 0.1717 | 2ìœ„ |
| **EDSNet** | **0.0457** | 0.1158 | 0.1659 | 3ìœ„ |
| **VideoSAGE** | 0.0443 | 0.0810 | 0.1175 | 4ìœ„ |

**ì£¼ìš” ë°œê²¬:**
- **LoGoNet**ì´ ëª¨ë“  ëª¨ë¸ ì¤‘ ìµœê³ ì˜ ìˆœìœ„ ìƒê´€ê³„ìˆ˜ ì„±ëŠ¥ ë‹¬ì„±
  - Spearman's Rho: 0.1909 (CSTA ëŒ€ë¹„ 11.1% í–¥ìƒ)
  - Kendall's Tau: 0.1336 (CSTA ëŒ€ë¹„ 11.7% í–¥ìƒ)
- ë¹„ë””ì˜¤ ìš”ì•½ íƒœìŠ¤í¬ì—ì„œëŠ” ìˆœìœ„ ìƒê´€ê³„ìˆ˜ê°€ Test Lossë³´ë‹¤ ë” ì¤‘ìš”í•œ í‰ê°€ ì§€í‘œì„ì„ í™•ì¸

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

### 1. CSTA (CNN-based Spatiotemporal Attention)
- **ë…¼ë¬¸**: CVPR 2024
- **êµ¬ì¡°**: 2D CNN + Attention ê¸°ë°˜
- **íŠ¹ì§•**: CNN attentionìœ¼ë¡œ localê³¼ global ì •ë³´ í¬ì°©

### 2. VideoSAGE (Video Summarization with Graph Representation Learning)
- **ë…¼ë¬¸**: CVPRW 2024
- **êµ¬ì¡°**: GCN ê¸°ë°˜ ê·¸ë˜í”„ ëª¨ë¸ë§
- **íŠ¹ì§•**: í”„ë ˆì„ì„ ê·¸ë˜í”„ ë…¸ë“œë¡œ ëª¨ë¸ë§í•˜ì—¬ ë³µì¡í•œ ê´€ê³„ í•™ìŠµ

### 3. EDSNet (Efficient-DSNet)
- **ë…¼ë¬¸**: arXiv 2024
- **êµ¬ì¡°**: Token Mixer (MLP-Mixer) ê¸°ë°˜ ê²½ëŸ‰ ëª¨ë¸
- **íŠ¹ì§•**: Attention ì—†ì´ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì „ì—­ ì •ë³´ ì²˜ë¦¬

### 4. LoGoNet (Local-Global Network) - **ì œì•ˆ ëª¨ë¸**
- **í•µì‹¬ ì•„ì´ë””ì–´**: Local Patternsì™€ Global Contextë¥¼ ë™ì‹œì— ëª¨ë¸ë§í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜
- **êµ¬ì¡°**:
  1. **Local Path**: 2D CNNìœ¼ë¡œ ì¸ì ‘ í”„ë ˆì„ ê°„ ì‹œê°„ì  íŒ¨í„´ ì¶”ì¶œ
  2. **Global Path**: Transformer Encoderë¡œ ì „ì²´ ì‹œí€€ìŠ¤ ë§¥ë½ í•™ìŠµ
  3. **Cross-Path Attention**: ë‘ ê²½ë¡œ ê°„ ì–‘ë°©í–¥ ì •ë³´ êµí™˜
  4. **Adaptive Fusion**: ë™ì  ê°€ì¤‘ì¹˜ ê¸°ë°˜ íŠ¹ì§• ìœµí•©
  5. **Score Regression**: ìµœì¢… importance scores ì˜ˆì¸¡
- **ëª¨ë¸ íŒŒë¼ë¯¸í„°**: ì•½ 11.8M
- **ì£¼ìš” ê°œì„ ì‚¬í•­**:
  - Transformer ê¸°ë°˜ Global Pathë¡œ ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ í–¥ìƒ
  - Cross-Path Attentionìœ¼ë¡œ ìƒí˜¸ ë³´ì™„ì  í•™ìŠµ
  - Adaptive Fusionìœ¼ë¡œ ë§¥ë½ ì¸ì‹ ë™ì  ìœµí•©

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
.
â”œâ”€â”€ README.md                 # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
â”œâ”€â”€ TERM_PROJECT_REPORT.md    # ì‹¤í—˜ ë³´ê³ ì„œ
â”œâ”€â”€ train.py                  # í†µí•© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ test.py                   # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ dataset.py                # ë°ì´í„°ì…‹ ë¡œë”
â”œâ”€â”€ models/                   # ëª¨ë¸ êµ¬í˜„
â”‚   â”œâ”€â”€ csta.py
â”‚   â”œâ”€â”€ videosage.py
â”‚   â”œâ”€â”€ edsnet.py
â”‚   â””â”€â”€ logonet.py           # ì œì•ˆ ëª¨ë¸
â”œâ”€â”€ data/                     # ë°ì´í„°ì…‹ ê´€ë ¨ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ evaluation/               # í‰ê°€ ì§€í‘œ
â”œâ”€â”€ utils/                    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ results/                  # ì‹¤í—˜ ê²°ê³¼
â””â”€â”€ (checkpoints/)            # ë¡œì»¬ì—ì„œë§Œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (ì œì¶œ/ê¹ƒí—ˆë¸Œì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ)
```

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰

### í™˜ê²½ ì„¤ì •

```bash
# Conda í™˜ê²½ í™œì„±í™”
source $HOME/miniconda3/etc/profile.d/conda.sh
conda activate mrhisum

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision scipy tqdm h5py
```

### ë°ì´í„°ì…‹ ì¤€ë¹„

ë°ì´í„°ì…‹ì€ `dataset/` ë””ë ‰í† ë¦¬ì— ë‹¤ìŒ íŒŒì¼ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:
- `mr_hisum.h5`: HDF5 í˜•ì‹ì˜ ë¹„ë””ì˜¤ íŠ¹ì§• ë° GT
- `mr_hisum_split.json`: Train/Val/Test Split ì •ë³´

### ëª¨ë¸ í•™ìŠµ

```bash
# LoGoNet í•™ìŠµ (ì œì•ˆ ëª¨ë¸)
python train.py \
    --model logonet \
    --batch_size 8 \
    --epochs 50 \
    --lr 1e-4 \
    --max_grad_norm 0.5

# ë‹¤ë¥¸ ëª¨ë¸ í•™ìŠµ
python train.py --model csta --batch_size 4 --epochs 50
python train.py --model videosage --batch_size 256 --epochs 50
python train.py --model edsnet --batch_size 112 --epochs 300
```

### ëª¨ë¸ í…ŒìŠ¤íŠ¸

```bash
# í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸
python test.py \
    --model logonet \
    --checkpoint /path/to/logonet_best.pth \  # ë¡œì»¬ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
    --batch_size 8 \
    --output_file results/logonet_test.txt
```

## ğŸ“Š ì‹¤í—˜ ì„¤ì •

### í•˜ì´í¼íŒŒë¼ë¯¸í„°

| ëª¨ë¸ | ë°°ì¹˜ ì‚¬ì´ì¦ˆ | Epochs | Peak LR | LR Scheduler |
|------|-----------|--------|---------|--------------|
| CSTA | 4 | 50 | 3e-4 | Warmup(3) + Cosine annealing|
| VideoSAGE | 512 | 50 | 5e-4 | Warmup(5) + Cosine annealing |
| EDSNet | 112 | 300 | 5e-5 | Fixed |
| LoGoNet | 8 | 50 | 1e-4 | Warmup(10) + Cosine annealing |

### í‰ê°€ ì§€í‘œ

- **Kendall's Tau**: ìˆœìœ„ ìƒê´€ê³„ìˆ˜ (ë‘ ìˆœìœ„ ê°„ ì¼ì¹˜ë„ ì¸¡ì •)
- **Spearman's Rho**: ìˆœìœ„ ìƒê´€ê³„ìˆ˜ (ëª¨ë…¸í†¤ ê´€ê³„ ì¸¡ì •)
- **Test Loss**: MSE Loss

## ğŸ“ ì£¼ìš” íŒŒì¼ ì„¤ëª…

- `TERM_PROJECT_REPORT.md`: ìƒì„¸í•œ ì‹¤í—˜ ë³´ê³ ì„œ ë° ê²°ê³¼ ë¶„ì„
- `train.py`: í†µí•© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ëª¨ë“  ëª¨ë¸ ì§€ì›)
- `test.py`: í…ŒìŠ¤íŠ¸ ì…‹ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- `models/logonet.py`: ì œì•ˆ ëª¨ë¸ LoGoNet êµ¬í˜„
- `results/`: ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ë“¤

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **Framework**: PyTorch
- **Hardware**: NVIDIA RTX 3080 (10GB VRAM)
- **Dataset**: MR.HiSum (Canonical Split)
- **Mixed Precision**: torch.cuda.amp (VRAM íš¨ìœ¨)

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. MR.HiSum Dataset
2. Rethinking the Evaluation of Video Summaries(CVPR 2019)
3. CSTA: CNN-based Spatiotemporal Attention for Video Summarization (CVPR 2024)
4. VideoSAGE: Video Summarization with Graph Representation Learning (CVPR 2024)
5. EDSNet: Efficient-DSNet (arXiv 2024)

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ë³¸ í”„ë¡œì íŠ¸ëŠ” í•™ìˆ  ì—°êµ¬ ëª©ì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ‘¤ ì‘ì„±ì

2025ë…„ 11ì›” 22ì¼ ~ 2025ë…„ 11ì›” 30ì¼

---

**ì°¸ê³ **: WandB(Weights & Biases)ëŠ” ì„ íƒì‚¬í•­ì´ë©°, `--use_wandb` í”Œë˜ê·¸ë¡œ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

